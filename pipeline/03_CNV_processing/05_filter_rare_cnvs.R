# Packages
# library(remotes)
# install_github(repo = "JH-Zhou/HandyCNV")
library(HandyCNV)
library(tibble)
library(stringr)
library(plyr)
source("scripts/util_load_cnvs.R")
#Paths
setwd("/data/NCR_SBRB/jungbt/CNV/ABCD")

#Load pipeline
pipeline <- commandArgs(trailingOnly = TRUE)[1]

dir.create(file.path("results",pipeline,"common"), recursive = TRUE)
dir.create(file.path("results",pipeline,"rare"), recursive = TRUE)

# Load subjects
sub_df <- read.csv(file.path("results",pipeline,"subject_info.csv"))
#Remove excluded subjects
sub_df <- sub_df[!startsWith(sub_df$ever_ADHD,"EXCLUDE"),]
#Count number of subjects
n_subs <- dim(sub_df)[1]

cnv_df <- read.csv(file.path("results",pipeline,"processed_cnvs.csv"))
#Reformat to HandyCNV Format
cnv_df <- as_tibble(cnv_df)
cnv_df <- cnv_df[c("ID","chr","start","end","cn")]
cnv_df$chr <- unlist(lapply(cnv_df$chr,function(x) str_replace(x,"chr","")))
colnames(cnv_df) <- c("Sample_ID", "Chr", "Start", "End", "CNV_Value")

#Call All CNVs (Common + Rare)
cnv_standard <- cnv_clean(standard_cnv = cnv_df,
                 folder = file.path("results",pipeline,"common","cnv"))

#Define CNVRs (Common + Rare)
cnvr_ars <- call_cnvr(clean_cnv = cnv_standard,
                 chr_set = 22,
                 folder = file.path("results",pipeline,"common","cnvr"))

#Get Reference Genome
Human_hg19 <- get_refgene(gene_version = "Human_hg19")

# Get genes overlapping with all CNVs
genes <- call_gene(refgene = "refgene/Human_hg19.txt",
          interval = cnvr_ars, #optional, standard file was generated by 'call_cnvr' function in section 4
          clean_cnv = cnv_standard, #optional, standard file was generated by 'cnv_clean' function in section 1
          folder = file.path("results",pipeline,"common","genes"))

#Calculate CNVR sample frequency and CNVR length
cnvr_ars$Frequency = cnvr_ars$n_Sample/n_subs
cnvr_ars$Length = cnvr_ars$End - cnvr_ars$Start

#Define common CNVRs.
common_cnvs <- cnvr_ars[cnvr_ars$Frequency > 0.01]

#BUT, this is too much. We need to remove only the segments of these CNVRs that
# are common. We'll segment each CNVR into chunks of 10,000 and assess their
# frequency

#Loop through each common CNV in segments of 10,000
common_cnvs_seg <- tibble()
i <- 1
for (cnv in rownames(common_cnvs)) {
  cnv <- as.integer(cnv)
  #Define bounds of segment
  start <- round_any(common_cnvs$Start[cnv], 10000, f = floor)
  end   <- round_any(common_cnvs$End[cnv], 10000, f = ceiling)
  #Limit CNVR segments to only those in a single chromosome
  cnvr_sub_df <- cnv_df[(cnv_df$Chr == common_cnvs$Chr[cnv]) & (cnv_df$Start >= common_cnvs$Start[cnv]) & (cnv_df$End <= common_cnvs$End[cnv]),]
  #Loop through segment
  for (n in seq(from=start+ 10000,to=end,by=10000)) {
    #Enter new row for segment
    common_cnvs_seg[i,"CNVR_ID"] <- common_cnvs$CNVR_ID[cnv]
    common_cnvs_seg[i,"Chr"] <- common_cnvs$Chr[cnv]
    common_cnvs_seg[i,"Start"] <- n - 10000
    common_cnvs_seg[i,"End"] <- n
    #Find CNVs that are in this segment
    common_cnvs_seg[i,"n_Sample"] <- sum(((n - 10000 >= cnvr_sub_df$Start) & (n - 10000 <= cnvr_sub_df$End)) |
    ((n >= cnvr_sub_df$Start) & (n <= cnvr_sub_df$End)))
    i = i + 1
  }
}

# Filter out CNVs smaller than 50 kb.
print(head(cnv_df))
cnv_df$length = cnv_df$End - cnv_df$Start
cnv_df <- cnv_df[cnv_df$length >= 50000,c("Sample_ID", "Chr", "Start", "End", "CNV_Value")]
print(head(cnv_df))
#Write common + rare CNVs to file
write.csv(cnv_df,file.path("results",pipeline,"processed_cnvs_common.csv"),row.names=FALSE)

#Define segment frequency
common_cnvs_seg$Frequency <- common_cnvs_seg$n_Sample/n_subs
#Filter for only common segments
common_cnvs_seg <- common_cnvs_seg[common_cnvs_seg$Frequency > 0.01,]
n = 1

#Combine CNV segments with frequency > 1 %
for (i in rownames(common_cnvs_seg)){
  i <- as.integer(i)
  if (i == 1) {
    #Start the exclusion DF
    exclude_cnvs <- common_cnvs_seg[i,]
  } else if (common_cnvs_seg[i,"Start"] == exclude_cnvs[n,"End"]) {
    #If the end of the next segment matches the start of the previous segment, append thme
    exclude_cnvs[n,"End"] <- common_cnvs_seg[i,"End"]
    exclude_cnvs[n,"n_Sample"] <- max(common_cnvs_seg[n,"n_Sample"],common_cnvs_seg[i,"n_Sample"])
    exclude_cnvs[n,"Frequency"] <- max(common_cnvs_seg[n,"Frequency"],common_cnvs_seg[i,"Frequency"])
  } else {
    #Start a new segment
    n = n + 1
    exclude_cnvs[n,] <- common_cnvs_seg[i,]
  }
}

#Save common segments
write.csv(exclude_cnvs,file.path("results",pipeline,"common_cnv_segments.csv"),row.names=FALSE)


#Remove CNVs that overlap with these "common" segments
for (cnv in 1:nrow(exclude_cnvs)) {
  print(head(cnv_df))
  cnv_df <- cnv_df[!((cnv_df$Chr == common_cnvs$Chr[cnv]) & (cnv_df$Start >= common_cnvs$Start[cnv]) & (cnv_df$End <= common_cnvs$End[cnv])),]
}


#Regenerate CNVRs
#Call Rare CNVs
cnv_standard <- cnv_clean(standard_cnv = cnv_df,
                 folder = file.path("results",pipeline,"rare","cnv"))

#Define rare CNVRs
cnvr_ars <- call_cnvr(clean_cnv = cnv_standard, #standard file was generated by 'cnv_clean' function in section 1
                 chr_set = 22, #Set the maximum number of chromosomes (29 autosomes for cattle)
                 folder = file.path("results",pipeline,"rare","cnvr"))
#Define length of rare CNVRs
cnvr_ars$Frequency = cnvr_ars$n_Sample/n_subs
cnvr_ars$Length = cnvr_ars$End - cnvr_ars$Start

# Save rare CNVRs
write.csv(cnv_df,file.path("results",pipeline,"processed_cnvs_rare.csv"),row.names=FALSE)

# Get genes overlapping with rare CNVs
genes <- call_gene(refgene = "refgene/Human_hg19.txt",
          interval = cnvr_ars, #optional, standard file was generated by 'call_cnvr' function in section 4
          clean_cnv = cnv_standard, #optional, standard file was generated by 'cnv_clean' function in section 1
          folder = file.path("results",pipeline,"rare","genes"))
